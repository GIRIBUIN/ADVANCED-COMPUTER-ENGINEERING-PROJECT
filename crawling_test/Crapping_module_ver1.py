import time
import pandas as pd
import traceback
import random
import os
import shutil
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException, TimeoutException
from selenium.webdriver.common.action_chains import ActionChains

# [í•„ìˆ˜] ë³‘ë ¬ ì²˜ë¦¬ ë° ë½(Lock) ê´€ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from multiprocessing import Pool, freeze_support, Manager

# --- ì„¤ì • ---
TARGET_RATINGS = ['ìµœê³ ', 'ì¢‹ìŒ', 'ë³´í†µ', 'ë³„ë¡œ', 'ë‚˜ì¨']
MAX_REVIEWS_PER_RATING = 100

def setup_driver(lock=None):
    """
    undetected_chromedriver ì´ˆê¸°í™”
    [ì¤‘ìš”] Lockì„ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ í”„ë¡œì„¸ìŠ¤ê°€ ë™ì‹œì— ë“œë¼ì´ë²„ íŒŒì¼ì„ ê±´ë“œë¦¬ëŠ” ê²ƒì„ ë°©ì§€
    """
    options = uc.ChromeOptions()
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("--start-maximized")
    # options.add_argument("--headless") # í•„ìš” ì‹œ ì£¼ì„ í•´ì œ
    
    driver = None
    
    # ë½(Lock)ì„ íšë“í•œ í”„ë¡œì„¸ìŠ¤ë§Œ ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì§„ì…
    if lock:
        lock.acquire()
    
    try:
        # print(f"   [ì‹œìŠ¤í…œ] ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì¤‘... (PID: {os.getpid()})")
        # ë²„ì „ 141ë¡œ ê°•ì œ ì§€ì • (ì‚¬ìš©ì í¬ë¡¬ ë²„ì „ì— ë§ì¶¤)
        driver = uc.Chrome(options=options, version_main=141)
    except Exception as e:
        print(f"   [ë“œë¼ì´ë²„ ì˜¤ë¥˜] 141ë²„ì „ ì‹¤íŒ¨, ì¬ì‹œë„... ì˜¤ë¥˜: {e}")
        try:
            # ì‹¤íŒ¨ ì‹œ ì•ˆì „ ì¥ì¹˜ (ë²„ì „ ë¯¸ì§€ì •)
            driver = uc.Chrome(options=options)
        except Exception as e2:
            print(f"   [ì¹˜ëª…ì  ì˜¤ë¥˜] ë“œë¼ì´ë²„ ë¡œë“œ ì™„ì „ ì‹¤íŒ¨: {e2}")
    finally:
        # ë“œë¼ì´ë²„ ë¡œë“œê°€ ëë‚˜ë©´(ì„±ê³µí•˜ë“  ì‹¤íŒ¨í•˜ë“ ) ë½ í•´ì œ -> ë‹¤ìŒ í”„ë¡œì„¸ìŠ¤ ì§„ì… í—ˆìš©
        if lock:
            # íŒŒì¼ ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ ë½ í•´ì œ ì „ ì•½ê°„ì˜ í…€ì„ ë‘ 
            time.sleep(2) 
            lock.release()
            
    return driver

def extract_reviews(driver, current_rating_filter):
    """ë¦¬ë·° ë°ì´í„° ì¶”ì¶œ (í•„í„° ì „/í›„ ê²¸ìš©)"""
    reviews_data = []
    review_article_xpath = "//article[contains(@class, 'sdp-review__article__list') or contains(@class, 'twc-pt-[16px]')]"

    try:
        WebDriverWait(driver, 10).until(
            EC.presence_of_all_elements_located((By.XPATH, review_article_xpath))
        )
    except TimeoutException:
        return []

    articles = driver.find_elements(By.XPATH, review_article_xpath)
    
    for article in articles:
        try:
            def get_text(selector):
                try: return article.find_element(By.CSS_SELECTOR, selector).text.strip()
                except: return ""

            author = article.find_element(By.CSS_SELECTOR, "span[data-member-id]").text.strip()
            rating = len(article.find_elements(By.CSS_SELECTOR, "i.twc-bg-full-star"))
            
            date = get_text("div.sdp-review__article__list__info__product-info__reg-date")
            if not date: 
                date = article.find_element(By.XPATH, ".//div[i[contains(@class, 'twc-bg-full-star')]]/following-sibling::div").text.strip()
            
            product_option = get_text("div.sdp-review__article__list__info__product-info__name")
            if not product_option: 
                product_option = get_text("div.twc-my-\\[16px\\]")
            
            review_title = get_text("div.sdp-review__article__list__headline")
            if not review_title: 
                review_title = get_text("div.twc-mb-\\[8px\\].twc-font-bold")

            review_body = get_text("div.sdp-review__article__list__review__content")
            if not review_body: 
                review_body = get_text("div.twc-break-all")
            
            helpful = 0
            try: 
                helpful = int(article.find_element(By.CSS_SELECTOR, "div.sdp-review__article__list__help").get_attribute("data-count"))
            except: 
                try:
                    helpful_text = article.find_element(By.XPATH, ".//div[contains(text(), 'ëª…ì—ê²Œ ë„ì›€ë˜ì—ˆìŠµë‹ˆë‹¤.')]").text
                    helpful = int(helpful_text.split('ëª…')[0].replace(',', '').strip())
                except:
                    pass
            
            reviews_data.append({
                "ë³„ì í•„í„°": current_rating_filter,
                "ì‘ì„±ì": author, "í‰ì ": rating, "ë‚ ì§œ": date, "êµ¬ë§¤ì˜µì…˜": product_option,
                "ì œëª©": review_title, "ë‚´ìš©": review_body, "ë„ì›€ë¨": helpful
            })
        except: 
            continue
    return reviews_data

def apply_rating_filter(driver, wait, rating_name):
    """ë³„ì  í•„í„° ì ìš©"""
    try:
        filter_btn = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, "div[role='combobox']")))
        
        if rating_name in filter_btn.text and "ëª¨ë“  ë³„ì " not in filter_btn.text:
            return True

        driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", filter_btn)
        time.sleep(1)
        filter_btn.click()
        time.sleep(1)

        popup = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, "[data-radix-popper-content-wrapper]")))
        option = popup.find_element(By.XPATH, f".//div[contains(text(), '{rating_name}')]")
        option.click()
        
        wait.until(EC.invisibility_of_element_located((By.CSS_SELECTOR, "[data-radix-popper-content-wrapper]")))
        time.sleep(3) 
        return True
    except Exception as e:
        print(f"[{rating_name}] í•„í„° ì ìš© ì‹¤íŒ¨: {str(e)[:50]}")
        return False

def scrape_single_rating(target_url, rating_name, lock):
    """í•˜ë‚˜ì˜ ë³„ì ì— ëŒ€í•´ ë¸Œë¼ìš°ì €ë¥¼ ìƒˆë¡œ ì—´ê³  ìˆ˜ì§‘"""
    
    # setup_driver í˜¸ì¶œ ì‹œ lock ì „ë‹¬
    driver = setup_driver(lock)
    if not driver:
        return []

    collected = []
    print(f"START: [{rating_name}] ë¸Œë¼ìš°ì € ë¡œë“œ ì™„ë£Œ, ìˆ˜ì§‘ ì‹œì‘")
    
    try:
        wait = WebDriverWait(driver, 30)
        driver.get(target_url)
        time.sleep(3) 

        review_tab = wait.until(EC.element_to_be_clickable((By.XPATH, "//a[contains(text(),'ìƒí’ˆí‰')]")))
        ActionChains(driver).move_to_element(review_tab).click().perform()
        
        review_section = wait.until(EC.presence_of_element_located((By.ID, "sdpReview")))
        driver.execute_script("arguments[0].scrollIntoView(true);", review_section)
        time.sleep(2) 

        if not apply_rating_filter(driver, wait, rating_name):
            print(f"FAIL: [{rating_name}] í•„í„° ì ìš© ë¶ˆê°€")
            return []

        visited_pages = set()
        while len(collected) < MAX_REVIEWS_PER_RATING:
            try:
                pagination_xpath = "//div[@data-page and @data-start and @data-end]"
                is_new_ui = False 
                try:
                    pagination = WebDriverWait(driver, 10).until(
                        EC.presence_of_element_located((By.XPATH, pagination_xpath))
                    )
                    if "twc-mt-[24px]" in pagination.get_attribute("class"):
                        is_new_ui = True
                except TimeoutException:
                    pagination = None 

                if pagination:
                    try:
                        if is_new_ui:
                            current_page = int(pagination.find_element(By.CSS_SELECTOR, "button[class*='twc-text-[#346aff]']").text.strip())
                        else:
                            current_page = int(pagination.find_element(By.CSS_SELECTOR, "button.selected").text.strip())
                    except Exception:
                        current_page = 1 
                else:
                    current_page = 1

                if current_page not in visited_pages:
                    new_reviews = extract_reviews(driver, rating_name)
                    if new_reviews:
                        collected.extend(new_reviews)
                        visited_pages.add(current_page)
                        print(f"ING: [{rating_name}] {current_page}í˜ì´ì§€ {len(new_reviews)}ê°œ ìˆ˜ì§‘ (ëˆ„ì : {len(collected)})")
                    else:
                         if pagination is None and current_page == 1:
                             break 
                         time.sleep(2)

                if len(collected) >= MAX_REVIEWS_PER_RATING: break

                if pagination:
                    next_btn = None
                    min_val = float('inf')

                    if is_new_ui:
                        page_buttons = pagination.find_elements(By.XPATH, ".//button[span]")
                        for btn in page_buttons:
                            try:
                                val = int(btn.text.strip())
                                if val not in visited_pages and val > current_page and val < min_val:
                                    min_val = val
                                    next_btn = btn
                            except: continue 
                    else:
                        for btn in pagination.find_elements(By.CSS_SELECTOR, "button.sdp-review__article__page__num"):
                            val = int(btn.text.strip())
                            if val not in visited_pages and val > current_page and val < min_val:
                                min_val = val
                                next_btn = btn
                    
                    if next_btn:
                        next_btn.click()
                        time.sleep(random.uniform(2.5, 4.0)) 
                    else:
                        try:
                            next_group = pagination.find_element(By.XPATH, ".//button[.//svg[not(contains(@class, 'twc-rotate'))]]")
                            if next_group.is_enabled() and next_group.get_attribute("disabled") is None:
                                current_start_val = None
                                if not is_new_ui:
                                    current_start_val = pagination.get_attribute("data-start")
                                next_group.click()
                                if not is_new_ui:
                                    wait.until(lambda d: d.find_element(By.XPATH, pagination_xpath).get_attribute("data-start") != current_start_val)
                                else:
                                    wait.until(EC.staleness_of(next_group)) 
                                time.sleep(random.uniform(2.5, 4.0))
                            else:
                                break
                        except NoSuchElementException:
                            break
                else:
                    break
            except Exception as page_e: 
                break
    except Exception as e:
        print(f"ERROR: [{rating_name}] ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
        traceback.print_exc()
    finally:
        if driver:
            print(f"END: [{rating_name}] ì¢…ë£Œ (ìµœì¢…: {len(collected)}ê°œ)")
            try: driver.quit()
            except: pass
    
    return collected[:MAX_REVIEWS_PER_RATING]

def scrape_wrapper(args):
    # args = (url, rating, lock)
    return scrape_single_rating(*args)

if __name__ == "__main__":
    freeze_support()

    target_url = "https://www.coupang.com/vp/products/7224339339?vendorItemId=3051369121&sourceType=SDP_ALSO_VIEWED"
    
    print("=== ë³‘ë ¬ ë¦¬ë·° ìŠ¤í¬ë˜í•‘ ì‹œì‘ (í”„ë¡œì„¸ìŠ¤ 5ê°œ ê°€ë™) ===")
    
    # [ì¤‘ìš”] Managerë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡œì„¸ìŠ¤ ê°„ ê³µìœ ë˜ëŠ” Lock ìƒì„±
    m = Manager()
    lock = m.Lock()

    # íŒŒë¼ë¯¸í„°ì— lock ì¶”ê°€
    tasks = [(target_url, rating, lock) for rating in TARGET_RATINGS]

    start_time = time.time()
    all_results = []

    with Pool(processes=len(TARGET_RATINGS)) as pool:
        results_list = pool.map(scrape_wrapper, tasks)
        for result in results_list:
            all_results.extend(result)

    end_time = time.time()
    print(f"\n=== ì „ì²´ ìˆ˜ì§‘ ì¢…ë£Œ (ì†Œìš” ì‹œê°„: {end_time - start_time:.2f}ì´ˆ) ===")

    if all_results:
        df = pd.DataFrame(all_results)
        file_name = "coupang_reviews_parallel_fixed.xlsx"
        df.to_excel(file_name, index=False)
        print(f"\nğŸ‰ [ì „ì²´ ì™„ë£Œ] ì´ {len(all_results)}ê°œì˜ ë¦¬ë·°ê°€ '{file_name}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print("\n[ì•Œë¦¼] ìˆ˜ì§‘ëœ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")
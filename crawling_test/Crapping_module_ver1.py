import time
import pandas as pd
import traceback
import random
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException, TimeoutException
from selenium.webdriver.common.action_chains import ActionChains

# --- ì„¤ì • ---
TARGET_RATINGS = ['ìµœê³ ', 'ì¢‹ìŒ', 'ë³´í†µ', 'ë³„ë¡œ', 'ë‚˜ì¨']
MAX_REVIEWS_PER_RATING = 100

def setup_driver():
    """undetected_chromedriver ì´ˆê¸°í™”"""
    options = uc.ChromeOptions()
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("--start-maximized")
    
    try:
        driver = uc.Chrome(options=options, version_main=141)
    except Exception as e:
        print(f"[ë“œë¼ì´ë²„ ë¡œë“œ ì˜¤ë¥˜] {e}")
        print("version_main=141ì„ ì œê±°í•˜ê³  ìë™ ê°ì§€ ëª¨ë“œë¡œ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤.")
        driver = uc.Chrome(options=options)
    return driver

def extract_reviews(driver, current_rating_filter):
    """ë¦¬ë·° ë°ì´í„° ì¶”ì¶œ (í•„í„° ì „/í›„ ê²¸ìš©)"""
    reviews_data = []
    
    review_article_xpath = "//article[contains(@class, 'sdp-review__article__list') or contains(@class, 'twc-pt-[16px]')]"

    try:
        WebDriverWait(driver, 10).until(
            EC.presence_of_all_elements_located((By.XPATH, review_article_xpath))
        )
    except TimeoutException:
        print(" Â  Â  -> 10ì´ˆ ëŒ€ê¸°í–ˆìœ¼ë‚˜ ë¦¬ë·° ìš”ì†Œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ë¦¬ë·° ì—†ìŒ ë˜ëŠ” ë¡œë”© ì‹¤íŒ¨)")
        return []

    articles = driver.find_elements(By.XPATH, review_article_xpath)
    
    for article in articles:
        try:
            def get_text(selector):
                try: return article.find_element(By.CSS_SELECTOR, selector).text.strip()
                except: return ""

            author = article.find_element(By.CSS_SELECTOR, "span[data-member-id]").text.strip()
            rating = len(article.find_elements(By.CSS_SELECTOR, "i.twc-bg-full-star"))
            date = get_text("div.sdp-review__article__list__info__product-info__reg-date")
            if not date: date = article.find_element(By.XPATH, ".//div[i[contains(@class, 'twc-bg-full-star')]]/following-sibling::div").text.strip()
            
            product_option = get_text("div.sdp-review__article__list__info__product-info__name")
            if not product_option: product_option = get_text("div.twc-my-\\[16px\\]")
            
            review_title = get_text("div.sdp-review__article__list__headline")
            if not review_title: review_title = get_text("div.twc-mb-\\[8px\\].twc-font-bold")

            review_body = get_text("div.sdp-review__article__list__review__content")
            if not review_body: review_body = get_text("div.twc-break-all")
            
            helpful = 0
            try: helpful = int(article.find_element(By.CSS_SELECTOR, "div.sdp-review__article__list__help").get_attribute("data-count"))
            except: pass
            
            reviews_data.append({
                "ë³„ì í•„í„°": current_rating_filter,
                "ì‘ì„±ì": author, "í‰ì ": rating, "ë‚ ì§œ": date, "êµ¬ë§¤ì˜µì…˜": product_option,
                "ì œëª©": review_title, "ë‚´ìš©": review_body, "ë„ì›€ë¨": helpful
            })
        except: 
            continue
    return reviews_data

def apply_rating_filter(driver, wait, rating_name):
    """ë³„ì  í•„í„° ì ìš©"""
    try:
        print(f" Â  -> ['{rating_name}'] í•„í„° ì ìš© ì‹œë„...")
        filter_btn = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, "div[role='combobox']")))
        
        if rating_name in filter_btn.text and "ëª¨ë“  ë³„ì " not in filter_btn.text:
            print(f" Â  Â  Â ['{rating_name}'] ì´ë¯¸ ì„ íƒë¨.")
            return True

        driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", filter_btn)
        time.sleep(1)
        filter_btn.click()
        time.sleep(1)

        popup = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, "[data-radix-popper-content-wrapper]")))
        option = popup.find_element(By.XPATH, f".//div[contains(text(), '{rating_name}')]")
        option.click()
        
        wait.until(EC.invisibility_of_element_located((By.CSS_SELECTOR, "[data-radix-popper-content-wrapper]")))
        print(f" Â  Â  Â ['{rating_name}'] í•„í„° ì ìš© ì™„ë£Œ. ë¡œë”© ëŒ€ê¸°...")
        time.sleep(3) 
        return True
    except Exception as e:
        print(f" Â  Â  Â [ì˜¤ë¥˜] í•„í„° ì ìš© ì‹¤íŒ¨: {str(e)[:50]}")
        return False

def scrape_single_rating(target_url, rating_name):
    """í•˜ë‚˜ì˜ ë³„ì ì— ëŒ€í•´ ë¸Œë¼ìš°ì €ë¥¼ ìƒˆë¡œ ì—´ê³  ìˆ˜ì§‘"""
    driver = None
    collected = []
    try:
        print(f"\n=== [{rating_name}] ìˆ˜ì§‘ ì‹œì‘ ===")
        driver = setup_driver()
        wait = WebDriverWait(driver, 30)
        driver.get(target_url)
        time.sleep(5)

        review_tab = wait.until(EC.element_to_be_clickable((By.XPATH, "//a[contains(text(),'ìƒí’ˆí‰')]")))
        ActionChains(driver).move_to_element(review_tab).click().perform()
        review_section = wait.until(EC.presence_of_element_located((By.ID, "sdpReview")))
        driver.execute_script("arguments[0].scrollIntoView(true);", review_section)
        time.sleep(2)

        if not apply_rating_filter(driver, wait, rating_name):
            print(f" Â  [ì‹¤íŒ¨] '{rating_name}' í•„í„° ì ìš© ë¶ˆê°€.")
            return []

        # --- [ í˜ì´ì§€ë„¤ì´ì…˜ ë¡œì§ v29 (ìˆ˜ì •ë¨) ] ---
        visited_pages = set()
        while len(collected) < MAX_REVIEWS_PER_RATING:
            try:
                # 1. í˜ì´ì§€ë„¤ì´ì…˜ ë°”(Bar) ê°ì§€
                pagination_xpath = "//div[@data-start and @data-end] | //div[contains(@class, 'twc-mt-[24px]')]"
                is_new_ui = False
                try:
                    pagination = WebDriverWait(driver, 10).until(
                        EC.presence_of_element_located((By.XPATH, pagination_xpath))
                    )
                    if "twc-mt-[24px]" in pagination.get_attribute("class"):
                        is_new_ui = True
                except TimeoutException:
                    pagination = None 

                # 2. í˜„ì¬ í˜ì´ì§€ ë²ˆí˜¸ í™•ì¸
                if pagination:
                    try:
                        if is_new_ui:
                            current_page = int(pagination.find_element(By.CSS_SELECTOR, "button[class*='twc-text-[#346aff]']").text.strip())
                        else:
                            current_page = int(pagination.find_element(By.CSS_SELECTOR, "button.selected").text.strip())
                    except Exception:
                        current_page = 1 
                else:
                    current_page = 1

                # 3. ë¦¬ë·° ìˆ˜ì§‘
                if current_page not in visited_pages:
                    new_reviews = extract_reviews(driver, rating_name)
                    if new_reviews:
                        collected.extend(new_reviews)
                        visited_pages.add(current_page)
                        print(f" Â  -> {current_page}í˜ì´ì§€: {len(new_reviews)}ê°œ ìˆ˜ì§‘ (ëˆ„ì : {len(collected)}/{MAX_REVIEWS_PER_RATING})")
                    else:
                         print(f" Â  -> {current_page}í˜ì´ì§€: ë¦¬ë·° ì—†ìŒ (ë¡œë”© ì§€ì—° ë˜ëŠ” ë§ˆì§€ë§‰ í˜ì´ì§€)")
                         if pagination is None and current_page == 1:
                             break 
                         time.sleep(2)

                if len(collected) >= MAX_REVIEWS_PER_RATING: break

                # 4. ë‹¤ìŒ í˜ì´ì§€ ì´ë™
                if pagination:
                    next_btn = None
                    min_val = float('inf')

                    if is_new_ui:
                        # [ìˆ˜ì •ë¨ v29] ìˆ«ì ë²„íŠ¼ë“¤: <span> íƒœê·¸ë¥¼ ê°€ì§„ ë²„íŠ¼
                        # (ì´ì „: .//button[span[number(text())]])
                        page_buttons = pagination.find_elements(By.XPATH, ".//button[span]")
                        for btn in page_buttons:
                            try:
                                val = int(btn.text.strip())
                                if val not in visited_pages and val > current_page and val < min_val:
                                    min_val = val
                                    next_btn = btn
                            except: continue 
                    else:
                        # [í•„í„° ì „] ë¡œì§ (ìœ ì§€)
                        for btn in pagination.find_elements(By.CSS_SELECTOR, "button.sdp-review__article__page__num"):
                            val = int(btn.text.strip())
                            if val not in visited_pages and val > current_page and val < min_val:
                                min_val = val
                                next_btn = btn
                    
                    if next_btn:
                        # 2, 3, 4 ë“± ë‹¤ìŒ í˜ì´ì§€ ë²ˆí˜¸ í´ë¦­
                        next_btn.click()
                        time.sleep(3)
                    else:
                        # '>' (ë‹¤ìŒ ê·¸ë£¹) ë²„íŠ¼ ì‹œë„
                        try:
                            # [ìˆ˜ì •ë¨ v29] '>' ë²„íŠ¼ì„ ë” ì •í™•í•˜ê²Œ ì°¾ìŒ
                            # '<' ë²„íŠ¼(twc-rotate)ì„ ì œì™¸í•œ svg ë²„íŠ¼
                            # (ì´ì „: .//button[last()][.//svg])
                            next_group = pagination.find_element(By.XPATH, ".//button[.//svg[not(contains(@class, 'twc-rotate'))]]")
                            
                            if next_group.is_enabled() and next_group.get_attribute("disabled") is None:
                                # [ìˆ˜ì •ë¨ v29] 'data-start' ì†ì„± ëŒ€ê¸° ë¡œì§ì€ 
                                # 'is_new_ui'ê°€ ì•„ë‹ ë•Œë§Œ(í•„í„° ì „) ì‹¤í–‰
                                current_start_val = None
                                if not is_new_ui:
                                    current_start_val = pagination.get_attribute("data-start")

                                next_group.click()
                                
                                if not is_new_ui:
                                    # [í•„í„° ì „] data-start ê°’ì´ ë°”ë€” ë•Œê¹Œì§€ ëŒ€ê¸°
                                    wait.until(lambda d: d.find_element(By.XPATH, pagination_xpath).get_attribute("data-start") != current_start_val)
                                else:
                                    # [í•„í„° í›„]ëŠ” data-startê°€ ì—†ìœ¼ë¯€ë¡œ, í˜ì´ì§€ ë²ˆí˜¸ê°€ ë°”ë€” ë•Œê¹Œì§€ ëŒ€ê¸° (ì˜ˆ: 11í˜ì´ì§€)
                                    wait.until(EC.staleness_of(next_group)) # '>' ë²„íŠ¼ì´ ì‚¬ë¼ì§ˆ ë•Œ(ì¬ë¡œë”©)ê¹Œì§€ ëŒ€ê¸°
                                
                                time.sleep(3)
                            else:
                                print(" Â  [ì™„ë£Œ] ë” ì´ìƒ í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ('>' ë²„íŠ¼ ë¹„í™œì„±í™”)")
                                break
                        except NoSuchElementException:
                            print(" Â  [ì™„ë£Œ] ë‹¤ìŒ ê·¸ë£¹(>) ë²„íŠ¼ ì—†ìŒ.")
                            break
                else:
                    print(" Â  [ì™„ë£Œ] ë‹¨ì¼ í˜ì´ì§€ì…ë‹ˆë‹¤. (í˜ì´ì§€ë„¤ì´ì…˜ ë°” ì—†ìŒ)")
                    break

            except Exception as page_e: 
                print(f" Â  [ì˜¤ë¥˜] í˜ì´ì§€ ìˆœíšŒ ì¤‘ ì—ëŸ¬: {page_e}")
                traceback.print_exc() 
                break

    except Exception as e:
        print(f" Â  [ì˜¤ë¥˜] {rating_name} ìˆ˜ì§‘ ì¤‘ ì—ëŸ¬: {e}")
        traceback.print_exc()
    finally:
        if driver:
            print(f"=== [{rating_name}] ì¢…ë£Œ (ìµœì¢… ìˆ˜ì§‘: {len(collected)}ê°œ) ===\n")
            try: driver.quit()
            except: pass
    
    return collected[:MAX_REVIEWS_PER_RATING]

if __name__ == "__main__":
    target_url = "https://www.coupang.com/vp/products/7224339339?vendorItemId=3051369121&sourceType=SDP_ALSO_VIEWED"
    
    all_results = []
    for rating in TARGET_RATINGS:
        rating_reviews = scrape_single_rating(target_url, rating)
        all_results.extend(rating_reviews)
        time.sleep(5)

    if all_results:
        df = pd.DataFrame(all_results)
        file_name = "coupang_reviews_final_v29_pagination_fix_2.xlsx"
        df.to_excel(file_name, index=False)
        print(f"\nğŸ‰ [ì „ì²´ ì™„ë£Œ] ì´ {len(all_results)}ê°œì˜ ë¦¬ë·°ê°€ '{file_name}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print("\n[ì•Œë¦¼] ìˆ˜ì§‘ëœ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")
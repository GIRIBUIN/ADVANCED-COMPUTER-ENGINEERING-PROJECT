import time
import pandas as pd
import traceback
import random
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException, TimeoutException
from selenium.webdriver.common.action_chains import ActionChains

# --- ì„¤ì • ---
TARGET_RATINGS = ['ìµœê³ ', 'ì¢‹ìŒ', 'ë³´í†µ', 'ë³„ë¡œ', 'ë‚˜ì¨']
MAX_REVIEWS_PER_RATING = 100

def setup_driver():
    """undetected_chromedriver ì´ˆê¸°í™”"""
    options = uc.ChromeOptions()
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("--start-maximized")
    
    try:
        driver = uc.Chrome(options=options, version_main=141)
    except Exception as e:
        print(f"[ë“œë¼ì´ë²„ ë¡œë“œ ì˜¤ë¥˜] {e}")
        print("version_main=141ì„ ì œê±°í•˜ê³  ìë™ ê°ì§€ ëª¨ë“œë¡œ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤.")
        driver = uc.Chrome(options=options)
    return driver

def extract_reviews(driver, current_rating_filter):
    """ë¦¬ë·° ë°ì´í„° ì¶”ì¶œ (í•„í„° ì „/í›„ ê²¸ìš©)"""
    reviews_data = []
    
    # ë¦¬ë·° articleì„ ì‹ë³„í•˜ëŠ” XPath (í•„í„° ì „/í›„ CSS í´ë˜ìŠ¤ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ í†µí•©)
    review_article_xpath = "//article[contains(@class, 'sdp-review__article__list') or contains(@class, 'twc-pt-[16px]')]"

    try:
        # ë¦¬ë·° ëª©ë¡ì´ ë¡œë“œë  ë•Œê¹Œì§€ ìµœì†Œ 1ê°œ ì´ìƒ ê¸°ë‹¤ë¦¼
        WebDriverWait(driver, 10).until(
            EC.presence_of_all_elements_located((By.XPATH, review_article_xpath))
        )
    except TimeoutException:
        print("     -> 10ì´ˆ ëŒ€ê¸°í–ˆìœ¼ë‚˜ ë¦¬ë·° ìš”ì†Œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ë¦¬ë·° ì—†ìŒ ë˜ëŠ” ë¡œë”© ì‹¤íŒ¨)")
        return []

    articles = driver.find_elements(By.XPATH, review_article_xpath)
    
    for article in articles:
        try:
            # ê³µìš© í•¨ìˆ˜: CSS ì…€ë ‰í„°ë¡œ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            def get_text(selector):
                try: return article.find_element(By.CSS_SELECTOR, selector).text.strip()
                except: return ""

            # ì‘ì„±ì (í•„ìˆ˜)
            author = article.find_element(By.CSS_SELECTOR, "span[data-member-id]").text.strip()
            
            # í‰ì  (í•„ìˆ˜) - ë³„ ì•„ì´ì½˜ ê°œìˆ˜ ê³„ì‚°
            rating = len(article.find_elements(By.CSS_SELECTOR, "i.twc-bg-full-star"))
            
            # ë‚ ì§œ (í•„í„° ì „/í›„ XPathê°€ ë‹¤ë¦„)
            date = get_text("div.sdp-review__article__list__info__product-info__reg-date")
            if not date: 
                # í•„í„° í›„ UI (twc-...)
                date = article.find_element(By.XPATH, ".//div[i[contains(@class, 'twc-bg-full-star')]]/following-sibling::div").text.strip()
            
            # êµ¬ë§¤ì˜µì…˜ (í•„í„° ì „/í›„ XPathê°€ ë‹¤ë¦„)
            product_option = get_text("div.sdp-review__article__list__info__product-info__name")
            if not product_option: 
                # í•„í„° í›„ UI (twc-...)
                product_option = get_text("div.twc-my-\\[16px\\]")
            
            # ë¦¬ë·° ì œëª© (í•„í„° ì „/í›„ XPathê°€ ë‹¤ë¦„)
            review_title = get_text("div.sdp-review__article__list__headline")
            if not review_title: 
                # í•„í„° í›„ UI (twc-...)
                review_title = get_text("div.twc-mb-\\[8px\\].twc-font-bold")

            # ë¦¬ë·° ë‚´ìš© (í•„í„° ì „/í›„ XPathê°€ ë‹¤ë¦„)
            review_body = get_text("div.sdp-review__article__list__review__content")
            if not review_body: 
                # í•„í„° í›„ UI (twc-...)
                review_body = get_text("div.twc-break-all")
            
            # ë„ì›€ë¨ (í•„í„° ì „/í›„ XPathê°€ ë‹¤ë¦„)
            helpful = 0
            try: 
                # í•„í„° ì „
                helpful = int(article.find_element(By.CSS_SELECTOR, "div.sdp-review__article__list__help").get_attribute("data-count"))
            except: 
                try:
                    # í•„í„° í›„
                    helpful_text = article.find_element(By.XPATH, ".//div[contains(text(), 'ëª…ì—ê²Œ ë„ì›€ë˜ì—ˆìŠµë‹ˆë‹¤.')]").text
                    helpful = int(helpful_text.split('ëª…')[0].replace(',', '').strip())
                except:
                    pass
            
            reviews_data.append({
                "ë³„ì í•„í„°": current_rating_filter,
                "ì‘ì„±ì": author, "í‰ì ": rating, "ë‚ ì§œ": date, "êµ¬ë§¤ì˜µì…˜": product_option,
                "ì œëª©": review_title, "ë‚´ìš©": review_body, "ë„ì›€ë¨": helpful
            })
        except: 
            # ê°œë³„ ë¦¬ë·° íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë‹¤ìŒ ë¦¬ë·°ë¡œ ë„˜ì–´ê°
            continue
    return reviews_data

def apply_rating_filter(driver, wait, rating_name):
    """ë³„ì  í•„í„° ì ìš©"""
    try:
        print(f"   -> ['{rating_name}'] í•„í„° ì ìš© ì‹œë„...")
        
        # í•„í„° ë“œë¡­ë‹¤ìš´ ë²„íŠ¼ ì°¾ê¸° (ì½¤ë³´ë°•ìŠ¤ ì—­í• )
        filter_btn = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, "div[role='combobox']")))
        
        # ì´ë¯¸ ì ìš©ë˜ì—ˆëŠ”ì§€ í…ìŠ¤íŠ¸ë¡œ í™•ì¸ (ì˜ˆ: 'ìµœê³ (123,456)')
        if rating_name in filter_btn.text and "ëª¨ë“  ë³„ì " not in filter_btn.text:
            print(f"       ['{rating_name}'] ì´ë¯¸ ì„ íƒë¨.")
            return True

        # ë²„íŠ¼ì„ í™”ë©´ ì¤‘ì•™ìœ¼ë¡œ ìŠ¤í¬ë¡¤ í›„ í´ë¦­
        driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", filter_btn)
        time.sleep(1) # ìŠ¤í¬ë¡¤ ì•ˆì •í™”
        filter_btn.click()
        time.sleep(1) # íŒì—… í‘œì‹œ ëŒ€ê¸°

        # ë³„ì  ì˜µì…˜ íŒì—… ì°¾ê¸°
        popup = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, "[data-radix-popper-content-wrapper]")))
        # íŒì—… ë‚´ì—ì„œ ì›í•˜ëŠ” ë³„ì  í…ìŠ¤íŠ¸(ì˜ˆ: 'ìµœê³ ')ë¥¼ ê°€ì§„ div í´ë¦­
        option = popup.find_element(By.XPATH, f".//div[contains(text(), '{rating_name}')]")
        option.click()
        
        # íŒì—…ì´ ì‚¬ë¼ì§ˆ ë•Œê¹Œì§€ ëŒ€ê¸° (ë¦¬ë·° ëª©ë¡ ë¦¬ë¡œë”© ì‹œì‘)
        wait.until(EC.invisibility_of_element_located((By.CSS_SELECTOR, "[data-radix-popper-content-wrapper]")))
        print(f"       ['{rating_name}'] í•„í„° ì ìš© ì™„ë£Œ. ë¡œë”© ëŒ€ê¸°...")
        time.sleep(3) # ë¦¬ë·° ëª©ë¡ì´ AJAXë¡œ ìƒˆë¡œê³ ì¹¨ë  ë•Œê¹Œì§€ ì¶©ë¶„íˆ ëŒ€ê¸°
        return True
    except Exception as e:
        print(f"       [ì˜¤ë¥˜] í•„í„° ì ìš© ì‹¤íŒ¨: {str(e)[:50]}")
        return False

def scrape_single_rating(target_url, rating_name):
    """í•˜ë‚˜ì˜ ë³„ì ì— ëŒ€í•´ ë¸Œë¼ìš°ì €ë¥¼ ìƒˆë¡œ ì—´ê³  ìˆ˜ì§‘"""
    driver = None
    collected = []
    try:
        print(f"\n=== [{rating_name}] ìˆ˜ì§‘ ì‹œì‘ ===")
        driver = setup_driver()
        wait = WebDriverWait(driver, 30)
        driver.get(target_url)
        time.sleep(5) # í˜ì´ì§€ ì´ˆê¸° ë¡œë“œ ëŒ€ê¸°

        # 'ìƒí’ˆí‰' íƒ­ìœ¼ë¡œ ì´ë™
        review_tab = wait.until(EC.element_to_be_clickable((By.XPATH, "//a[contains(text(),'ìƒí’ˆí‰')]")))
        ActionChains(driver).move_to_element(review_tab).click().perform()
        
        # ë¦¬ë·° ì„¹ì…˜(sdpReview)ì´ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
        review_section = wait.until(EC.presence_of_element_located((By.ID, "sdpReview")))
        driver.execute_script("arguments[0].scrollIntoView(true);", review_section)
        time.sleep(2) # ìŠ¤í¬ë¡¤ í›„ ê´€ë ¨ ìš”ì†Œ ë¡œë“œ ëŒ€ê¸°

        # ë³„ì  í•„í„° ì ìš©
        if not apply_rating_filter(driver, wait, rating_name):
            print(f"   [ì‹¤íŒ¨] '{rating_name}' í•„í„° ì ìš© ë¶ˆê°€.")
            return []

        # --- [ í˜ì´ì§€ë„¤ì´ì…˜ ë¡œì§ ] ---
        visited_pages = set()
        while len(collected) < MAX_REVIEWS_PER_RATING:
            try:
                # 1. í˜ì´ì§€ë„¤ì´ì…˜ ë°”(Bar) ê°ì§€
                
                # #############################################################
                # [ìˆ˜ì •ë¨] data-page, data-start, data-end ì†ì„±ì„ ëª¨ë‘ ê°€ì§„ divë¡œ ëª…í™•í•˜ê²Œ ì§€ì •
                pagination_xpath = "//div[@data-page and @data-start and @data-end]"
                # #############################################################
                
                is_new_ui = False # ê¸°ë³¸ê°’ì€ í•„í„° ì „ UIë¡œ ê°€ì •
                try:
                    # í˜ì´ì§€ë„¤ì´ì…˜ ë°”ê°€ ë¡œë“œë  ë•Œê¹Œì§€ 10ì´ˆ ëŒ€ê¸°
                    pagination = WebDriverWait(driver, 10).until(
                        EC.presence_of_element_located((By.XPATH, pagination_xpath))
                    )
                    # ìƒˆ UI(í•„í„° í›„)ì¸ì§€ í™•ì¸
                    if "twc-mt-[24px]" in pagination.get_attribute("class"):
                        is_new_ui = True
                except TimeoutException:
                    pagination = None # 10ì´ˆê°„ ëª»ì°¾ìœ¼ë©´ í˜ì´ì§€ë„¤ì´ì…˜ì´ ì—†ëŠ” ê²ƒ(1í˜ì´ì§€)ìœ¼ë¡œ ê°„ì£¼

                # 2. í˜„ì¬ í˜ì´ì§€ ë²ˆí˜¸ í™•ì¸
                if pagination:
                    try:
                        if is_new_ui:
                            # [í•„í„° í›„] í™œì„±í™”ëœ(íŒŒë€ìƒ‰) ë²„íŠ¼ì˜ í…ìŠ¤íŠ¸ë¥¼ í˜„ì¬ í˜ì´ì§€ë¡œ ì¸ì‹
                            current_page = int(pagination.find_element(By.CSS_SELECTOR, "button[class*='twc-text-[#346aff]']").text.strip())
                        else:
                            # [í•„í„° ì „] 'selected' í´ë˜ìŠ¤ë¥¼ ê°€ì§„ ë²„íŠ¼ (ê¸°ì¡´ ë¡œì§)
                            current_page = int(pagination.find_element(By.CSS_SELECTOR, "button.selected").text.strip())
                    except Exception:
                        current_page = 1 # ë²„íŠ¼ì„ ëª»ì°¾ìœ¼ë©´ 1í˜ì´ì§€ë¡œ ê°„ì£¼
                else:
                    current_page = 1

                # 3. ë¦¬ë·° ìˆ˜ì§‘
                if current_page not in visited_pages:
                    new_reviews = extract_reviews(driver, rating_name)
                    if new_reviews:
                        collected.extend(new_reviews)
                        visited_pages.add(current_page)
                        print(f"   -> {current_page}í˜ì´ì§€: {len(new_reviews)}ê°œ ìˆ˜ì§‘ (ëˆ„ì : {len(collected)}/{MAX_REVIEWS_PER_RATING})")
                    else:
                         print(f"   -> {current_page}í˜ì´ì§€: ë¦¬ë·° ì—†ìŒ (ë¡œë”© ì§€ì—° ë˜ëŠ” ë§ˆì§€ë§‰ í˜ì´ì§€)")
                         # í˜ì´ì§€ë„¤ì´ì…˜ ë°”ê°€ ì—†ëŠ”ë°(pagination is None) ë¦¬ë·°ë„ ì—†ìœ¼ë©´(1í˜ì´ì§€) ì¢…ë£Œ
                         if pagination is None and current_page == 1:
                             break 
                         time.sleep(2)

                if len(collected) >= MAX_REVIEWS_PER_RATING: break

                # 4. ë‹¤ìŒ í˜ì´ì§€ ì´ë™
                if pagination:
                    next_btn = None
                    min_val = float('inf')

                    if is_new_ui:
                        # [í•„í„° í›„] ë¡œì§
                        # ìˆ«ì ë²„íŠ¼ë“¤: <span> íƒœê·¸ë¥¼ ê°€ì§„ ë²„íŠ¼
                        page_buttons = pagination.find_elements(By.XPATH, ".//button[span]")
                        for btn in page_buttons:
                            try:
                                val = int(btn.text.strip())
                                # ë°©ë¬¸ ì•ˆ í–ˆê³ , í˜„ì¬ í˜ì´ì§€ë³´ë‹¤ í¬ê³ , ê°€ì¥ ì‘ì€ ë‹¤ìŒ í˜ì´ì§€ ì°¾ê¸°
                                if val not in visited_pages and val > current_page and val < min_val:
                                    min_val = val
                                    next_btn = btn
                            except: continue 
                    else:
                        # [í•„í„° ì „] ë¡œì§
                        for btn in pagination.find_elements(By.CSS_SELECTOR, "button.sdp-review__article__page__num"):
                            val = int(btn.text.strip())
                            if val not in visited_pages and val > current_page and val < min_val:
                                min_val = val
                                next_btn = btn
                    
                    if next_btn:
                        # 2, 3, 4 ë“± ë‹¤ìŒ í˜ì´ì§€ ë²ˆí˜¸ í´ë¦­
                        next_btn.click()
                        time.sleep(random.uniform(2.5, 4.0)) # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
                    else:
                        # '>' (ë‹¤ìŒ ê·¸ë£¹) ë²„íŠ¼ ì‹œë„
                        try:
                            # '>' ë²„íŠ¼: svgê°€ ìˆê³ , ê·¸ svgê°€ 'twc-rotate'(<) í´ë˜ìŠ¤ë¥¼ ê°–ì§€ ì•ŠìŒ
                            next_group = pagination.find_element(By.XPATH, ".//button[.//svg[not(contains(@class, 'twc-rotate'))]]")
                            
                            if next_group.is_enabled() and next_group.get_attribute("disabled") is None:
                                current_start_val = None
                                if not is_new_ui:
                                    # [í•„í„° ì „]ì€ data-start ì†ì„±ìœ¼ë¡œ í˜ì´ì§€ ê·¸ë£¹ ë³€ê²½ì„ ê°ì§€
                                    current_start_val = pagination.get_attribute("data-start")

                                next_group.click()
                                
                                if not is_new_ui:
                                    # [í•„í„° ì „] data-start ê°’ì´ ë°”ë€” ë•Œê¹Œì§€ ëŒ€ê¸°
                                    wait.until(lambda d: d.find_element(By.XPATH, pagination_xpath).get_attribute("data-start") != current_start_val)
                                else:
                                    # [í•„í„° í›„]ëŠ” data-startê°€ ì—†ìœ¼ë¯€ë¡œ, '>' ë²„íŠ¼ì´ ì‚¬ë¼ì§ˆ ë•Œ(ì¬ë¡œë”©)ê¹Œì§€ ëŒ€ê¸°
                                    wait.until(EC.staleness_of(next_group)) 
                                
                                time.sleep(random.uniform(2.5, 4.0)) # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
                            else:
                                print("   [ì™„ë£Œ] ë” ì´ìƒ í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ('>' ë²„íŠ¼ ë¹„í™œì„±í™”)")
                                break
                        except NoSuchElementException:
                            print("   [ì™„ë£Œ] ë‹¤ìŒ ê·¸ë£¹(>) ë²„íŠ¼ ì—†ìŒ.")
                            break
                else:
                    print("   [ì™„ë£Œ] ë‹¨ì¼ í˜ì´ì§€ì…ë‹ˆë‹¤. (í˜ì´ì§€ë„¤ì´ì…˜ ë°” ì—†ìŒ)")
                    break

            except Exception as page_e: 
                print(f"   [ì˜¤ë¥˜] í˜ì´ì§€ ìˆœíšŒ ì¤‘ ì—ëŸ¬: {page_e}")
                traceback.print_exc() 
                break

    except Exception as e:
        print(f"   [ì˜¤ë¥˜] {rating_name} ìˆ˜ì§‘ ì¤‘ ì—ëŸ¬: {e}")
        traceback.print_exc()
    finally:
        if driver:
            print(f"=== [{rating_name}] ì¢…ë£Œ (ìµœì¢… ìˆ˜ì§‘: {len(collected)}ê°œ) ===\n")
            try: driver.quit()
            except: pass
    
    return collected[:MAX_REVIEWS_PER_RATING]

if __name__ == "__main__":
    # ëŒ€ìƒ URL
    target_url = "https://www.coupang.com/vp/products/7224339339?vendorItemId=3051369121&sourceType=SDP_ALSO_VIEWED"
    
    all_results = []
    for rating in TARGET_RATINGS:
        rating_reviews = scrape_single_rating(target_url, rating)
        all_results.extend(rating_reviews)
        time.sleep(random.uniform(3, 6)) # ë‹¤ìŒ ë³„ì  ìˆ˜ì§‘ ì „ íœ´ì‹

    if all_results:
        df = pd.DataFrame(all_results)
        file_name = "coupang_reviews_final_fixed_v2.xlsx"
        df.to_excel(file_name, index=False)
        print(f"\nğŸ‰ [ì „ì²´ ì™„ë£Œ] ì´ {len(all_results)}ê°œì˜ ë¦¬ë·°ê°€ '{file_name}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print("\n[ì•Œë¦¼] ìˆ˜ì§‘ëœ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")